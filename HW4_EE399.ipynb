{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1fe54c",
   "metadata": {},
   "source": [
    "Chetana Iyer \n",
    "Github username: chetiyer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "303d2884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(1401.8444)\n",
      "Test loss: tensor(2446.0713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chetanaiyer/miniconda/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([31])) that is different to the input size (torch.Size([31, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/chetanaiyer/miniconda/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([20])) that is different to the input size (torch.Size([20, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/chetanaiyer/miniconda/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network and define the loss and optimizer\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X = torch.from_numpy(np.arange(0,31).reshape(-1,1).astype(np.float32))\n",
    "Y = torch.from_numpy(np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41,\n",
    "                                40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb22daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(1333.6720)\n",
      "Test loss: tensor(2355.3342)\n",
      "Training loss (ii): tensor(1661.1974)\n",
      "Test loss (ii): tensor(1485.2930)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chetanaiyer/miniconda/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([10, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# (ii) Using the first 20 data points as training data, fit the neural network\n",
    "X_train = X[:20]\n",
    "Y_train = Y[:20]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train)\n",
    "    loss = criterion(output, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Compute the least-square error for each of these over the training points\n",
    "with torch.no_grad():\n",
    "    train_loss = criterion(net(X_train), Y_train)\n",
    "    print('Training loss:', train_loss)\n",
    "\n",
    "# Compute the least square error of these models on the test data which are the remaining 10 data points\n",
    "X_test = X[20:]\n",
    "Y_test = Y[20:]\n",
    "with torch.no_grad():\n",
    "    test_loss = criterion(net(X_test), Y_test)\n",
    "    print('Test loss:', test_loss)\n",
    "\n",
    "\n",
    "# (iii) Repeat (iii) but use the first 10 and last 10 data points as training data\n",
    "X_train2 = torch.cat((X[:10], X[-10:]), dim=0)\n",
    "Y_train2 = torch.cat((Y[:10], Y[-10:]), dim=0)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = net(X_train2)\n",
    "    loss = criterion(output, Y_train2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Compute the least-square error for each of these over the training points\n",
    "with torch.no_grad():\n",
    "    train_loss2 = criterion(net(X_train2), Y_train2)\n",
    "    print('Training loss (ii):', train_loss2)\n",
    "\n",
    "# Fit the model to the test data (which are the 10 held out middle data points)\n",
    "X_test2 = X[10:20]\n",
    "Y_test2 = Y[10:20]\n",
    "with torch.no_grad():\n",
    "    test_loss2 = criterion(net(X_test2), Y_test2)\n",
    "    print('Test loss (ii):', test_loss2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22197d41",
   "metadata": {},
   "source": [
    "Homework 1 looked at fitting data to a line,parabola and 19th degree polynomial - for the first splitting 20 points of the data each evenly into training and test, the errors were respectively for\n",
    "\n",
    "training: \n",
    "line fitting - 100.59\n",
    "parabola - 90.35\n",
    "19th degree polynomial - 0.016\n",
    "\n",
    "and test  \n",
    "line fitting - 118.28\n",
    "parabola - 816.33\n",
    "19th degree polynomial - 9.014\n",
    "\n",
    "on which set, the neural networks performed worse with a training loss of 1333.67, and a test loss of 2355.33\n",
    "\n",
    "For the second division of the data, \n",
    "the respective values were \n",
    "\n",
    "training: \n",
    "line fitting - 68.57\n",
    "parabola - 68.51\n",
    "19th degree polynomial - 0.536\n",
    "\n",
    "and test  \n",
    "line fitting - 86.64\n",
    "parabola - 84.70\n",
    "19th degree polynomial - 2576550.371\n",
    "\n",
    "The training and test loss for the neural network was 1661.19 and 1485.2930 respectively. It performed better than the 19th degree polynomial on the testing data, but worse compared to both line fitting and parabola fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828bf9a3",
   "metadata": {},
   "source": [
    "# II Now train a feedforward neural network on the MNIST data set. You will start by performing the following analysis:\n",
    "### (i) Compute the first 20 PCA modes of the digit images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e505dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 9912422/9912422 [00:00<00:00, 50103714.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 28881/28881 [00:00<00:00, 4439156.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████| 1648877/1648877 [00:00<00:00, 9676121.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 4542/4542 [00:00<00:00, 3613529.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Flatten the images\n",
    "train_images = mnist_trainset.data.reshape(mnist_trainset.data.shape[0], -1)\n",
    "test_images = mnist_testset.data.reshape(mnist_testset.data.shape[0], -1)\n",
    "\n",
    "# Perform PCA on the training images\n",
    "pca = PCA(n_components=20)\n",
    "train_images_pca = pca.fit_transform(train_images)\n",
    "\n",
    "# Use the PCA model to transform the test images\n",
    "test_images_pca = pca.transform(test_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d55c3",
   "metadata": {},
   "source": [
    "### (ii) Build a feed-forward neural network to classify the digits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae6c831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9094666666666666\n",
      "Test accuracy: 0.9106\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network and define the loss and optimizer\n",
    "input_size = 20 # size of PCA output\n",
    "hidden_size = 50\n",
    "output_size = 10 # number of classes\n",
    "net = Net(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_labels = mnist_trainset.targets\n",
    "test_labels = mnist_testset.targets\n",
    "X_train = torch.from_numpy(train_images_pca.astype(np.float32))\n",
    "y_train = torch.from_numpy(train_labels.numpy())\n",
    "X_test = torch.from_numpy(test_images_pca.astype(np.float32))\n",
    "y_test = torch.from_numpy(test_labels.numpy())\n",
    "\n",
    "# Train the network\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        output = net(batch_X)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the network\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds = torch.argmax(net(X_train), axis=1)\n",
    "    test_preds = torch.argmax(net(X_test), axis=1)\n",
    "    train_acc = torch.sum(train_preds == y_train).item() / len(y_train)\n",
    "    test_acc = torch.sum(test_preds == y_test).item() / len(y_test)\n",
    "\n",
    "print(\"Training accuracy:\", train_acc)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5c6c0",
   "metadata": {},
   "source": [
    "## Compare the results of the neural network against LSTM, SVM (support vector machines) and decision tree classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "363c6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Flatten the images\n",
    "train_images = mnist_trainset.data.reshape(mnist_trainset.data.shape[0], -1)\n",
    "test_images = mnist_testset.data.reshape(mnist_testset.data.shape[0], -1)\n",
    "\n",
    "# Perform PCA on the training images\n",
    "pca = PCA(n_components=20)\n",
    "train_images_pca = pca.fit_transform(train_images)\n",
    "\n",
    "# Use the PCA model to transform the test images\n",
    "test_images_pca = pca.transform(test_images)\n",
    "\n",
    "# Load labels\n",
    "train_labels = mnist_trainset.targets.numpy()\n",
    "test_labels = mnist_testset.targets.numpy()\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "train_images_pca_tensor = torch.from_numpy(train_images_pca.astype(np.float32))\n",
    "train_labels_tensor = torch.from_numpy(train_labels)\n",
    "test_images_pca_tensor = torch.from_numpy(test_images_pca.astype(np.float32))\n",
    "test_labels_tensor = torch.from_numpy(test_labels)\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = TensorDataset(train_images_pca_tensor, train_labels_tensor)\n",
    "test_dataset = TensorDataset(test_images_pca_tensor, test_labels_tensor)\n",
    "\n",
    "# Set up the DataLoader objects\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Set up the model, loss function, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 20\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "model_lstm = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the LSTM model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(-1, 1, input_size).to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_lstm(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c458fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the LSTM model using scikit-learn accuracy score\n",
    "with torch.no_grad():\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 1, input_size).to(device)\n",
    "        outputs = model_lstm(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Test accuracy (LSTM): {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d498d",
   "metadata": {},
   "source": [
    "The Test accuracy (LSTM) of 0.0999 is significantly lower than the Training accuracy of 0.9094666666666666 for the LSTM model, and also much lower than the Test accuracy of 0.9106 for the feedforward neural network on the same dataset.\n",
    "\n",
    "This indicates that the LSTM model is overfitting to the training data and is not generalizing well to the test data. This could be due to various reasons such as suboptimal hyperparameters, insufficient training data, or insufficient regularization.\n",
    "\n",
    "It may be worth experimenting with different hyperparameters or regularization techniques to see if the performance of the LSTM model can be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172b414",
   "metadata": {},
   "source": [
    "# Evaluating against SVM and decision tree classifiers\n",
    "\n",
    "In the last homework assignment, we calculated the accuracy of SVM and decision tree classifiers in overall classification. The overall accuracy for classification for the SVM and Decision tree methods were 0.97628 and 0.8666. \n",
    "\n",
    "From this homework, we identified that the classification accuracy for the feed-forward neural network was 0.9106, and 0.0999 for the LSTM model. \n",
    "\n",
    "From this we can note the order of performance in classifying MNIST digits,  as 1) SVM, 2) FFNN 3) Decision tree and lastly LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2b071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
